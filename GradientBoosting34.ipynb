{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GradientBoosting34.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/m-aliabbas/Pneumonia-Train-Models-/blob/master/GradientBoosting34.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZ2qHEIHqOKS",
        "colab_type": "text"
      },
      "source": [
        "# Loading and Preprocessing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qBVybnmuWHi",
        "colab_type": "code",
        "outputId": "a300f47e-c259-4cd6-cfbe-a48aac830deb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJadp5X2wF15",
        "colab_type": "code",
        "outputId": "44562a61-34a6-4756-8f1a-85946629b184",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls '/content/drive/My Drive/PreTrainModels/'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dataset123.csv\tdatasetRes34.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NH-2YjdJLNB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "# Importing the dataset\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RO9gbhYOKA8W",
        "colab_type": "code",
        "outputId": "56bd1f69-0994-43a4-cbc0-7c9b9bd0828a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset = pd.read_csv('/content/drive/My Drive/PreTrainModels/datasetRes34.csv')\n",
        "dataset.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3680, 513)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvVWjDZ3qX5E",
        "colab_type": "text"
      },
      "source": [
        "#Split into Train , Validation and Test Sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYAJoivhJcdJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "dftrain,dftest= train_test_split(dataset, test_size=0.1, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mihv9RMqz5De",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dftrain,dfvalid= train_test_split(dftrain, test_size=0.2, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1R5g2Hblqe6E",
        "colab_type": "text"
      },
      "source": [
        "Getting Features Name"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZB5c63dLhHb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "featureCol=[]\n",
        "for i in range(512):\n",
        "    featureCol+=[str(i)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCdd6YcM0Ljo",
        "colab_type": "code",
        "outputId": "ffa294b3-5eff-41ed-a637-dbbaf297b9a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dftrain.shape,dfvalid.shape,dftest.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2649, 513), (663, 513), (368, 513))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eV09g6UPqilP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zuRIXDfiqnWi",
        "colab_type": "text"
      },
      "source": [
        "Ploting Historgram of Data in sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MTjAd3S0aFI",
        "colab_type": "code",
        "outputId": "47325110-7c74-40f4-bdd3-80962585120a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "dftrain['label'].hist()\n",
        "\n",
        "dfvalid['label'].hist()\n",
        "dftest['label'].hist()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f2e708e6dd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAJLUKANAkhplAEhSo/4fixpwDt95iQcAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiRT_RyoM3-j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "featureCol+=['label']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mnw0n3CXNGN6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testCol=featureCol[:512]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lsgPaDUNP9w",
        "colab_type": "code",
        "outputId": "8572428a-0322-4e41-f848-1871c7d77d7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(testCol)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "512"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjQi1E99qqyX",
        "colab_type": "code",
        "outputId": "015d16f9-73b0-4f1a-d4dd-66087b369737",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "featureCol"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['0',\n",
              " '1',\n",
              " '2',\n",
              " '3',\n",
              " '4',\n",
              " '5',\n",
              " '6',\n",
              " '7',\n",
              " '8',\n",
              " '9',\n",
              " '10',\n",
              " '11',\n",
              " '12',\n",
              " '13',\n",
              " '14',\n",
              " '15',\n",
              " '16',\n",
              " '17',\n",
              " '18',\n",
              " '19',\n",
              " '20',\n",
              " '21',\n",
              " '22',\n",
              " '23',\n",
              " '24',\n",
              " '25',\n",
              " '26',\n",
              " '27',\n",
              " '28',\n",
              " '29',\n",
              " '30',\n",
              " '31',\n",
              " '32',\n",
              " '33',\n",
              " '34',\n",
              " '35',\n",
              " '36',\n",
              " '37',\n",
              " '38',\n",
              " '39',\n",
              " '40',\n",
              " '41',\n",
              " '42',\n",
              " '43',\n",
              " '44',\n",
              " '45',\n",
              " '46',\n",
              " '47',\n",
              " '48',\n",
              " '49',\n",
              " '50',\n",
              " '51',\n",
              " '52',\n",
              " '53',\n",
              " '54',\n",
              " '55',\n",
              " '56',\n",
              " '57',\n",
              " '58',\n",
              " '59',\n",
              " '60',\n",
              " '61',\n",
              " '62',\n",
              " '63',\n",
              " '64',\n",
              " '65',\n",
              " '66',\n",
              " '67',\n",
              " '68',\n",
              " '69',\n",
              " '70',\n",
              " '71',\n",
              " '72',\n",
              " '73',\n",
              " '74',\n",
              " '75',\n",
              " '76',\n",
              " '77',\n",
              " '78',\n",
              " '79',\n",
              " '80',\n",
              " '81',\n",
              " '82',\n",
              " '83',\n",
              " '84',\n",
              " '85',\n",
              " '86',\n",
              " '87',\n",
              " '88',\n",
              " '89',\n",
              " '90',\n",
              " '91',\n",
              " '92',\n",
              " '93',\n",
              " '94',\n",
              " '95',\n",
              " '96',\n",
              " '97',\n",
              " '98',\n",
              " '99',\n",
              " '100',\n",
              " '101',\n",
              " '102',\n",
              " '103',\n",
              " '104',\n",
              " '105',\n",
              " '106',\n",
              " '107',\n",
              " '108',\n",
              " '109',\n",
              " '110',\n",
              " '111',\n",
              " '112',\n",
              " '113',\n",
              " '114',\n",
              " '115',\n",
              " '116',\n",
              " '117',\n",
              " '118',\n",
              " '119',\n",
              " '120',\n",
              " '121',\n",
              " '122',\n",
              " '123',\n",
              " '124',\n",
              " '125',\n",
              " '126',\n",
              " '127',\n",
              " '128',\n",
              " '129',\n",
              " '130',\n",
              " '131',\n",
              " '132',\n",
              " '133',\n",
              " '134',\n",
              " '135',\n",
              " '136',\n",
              " '137',\n",
              " '138',\n",
              " '139',\n",
              " '140',\n",
              " '141',\n",
              " '142',\n",
              " '143',\n",
              " '144',\n",
              " '145',\n",
              " '146',\n",
              " '147',\n",
              " '148',\n",
              " '149',\n",
              " '150',\n",
              " '151',\n",
              " '152',\n",
              " '153',\n",
              " '154',\n",
              " '155',\n",
              " '156',\n",
              " '157',\n",
              " '158',\n",
              " '159',\n",
              " '160',\n",
              " '161',\n",
              " '162',\n",
              " '163',\n",
              " '164',\n",
              " '165',\n",
              " '166',\n",
              " '167',\n",
              " '168',\n",
              " '169',\n",
              " '170',\n",
              " '171',\n",
              " '172',\n",
              " '173',\n",
              " '174',\n",
              " '175',\n",
              " '176',\n",
              " '177',\n",
              " '178',\n",
              " '179',\n",
              " '180',\n",
              " '181',\n",
              " '182',\n",
              " '183',\n",
              " '184',\n",
              " '185',\n",
              " '186',\n",
              " '187',\n",
              " '188',\n",
              " '189',\n",
              " '190',\n",
              " '191',\n",
              " '192',\n",
              " '193',\n",
              " '194',\n",
              " '195',\n",
              " '196',\n",
              " '197',\n",
              " '198',\n",
              " '199',\n",
              " '200',\n",
              " '201',\n",
              " '202',\n",
              " '203',\n",
              " '204',\n",
              " '205',\n",
              " '206',\n",
              " '207',\n",
              " '208',\n",
              " '209',\n",
              " '210',\n",
              " '211',\n",
              " '212',\n",
              " '213',\n",
              " '214',\n",
              " '215',\n",
              " '216',\n",
              " '217',\n",
              " '218',\n",
              " '219',\n",
              " '220',\n",
              " '221',\n",
              " '222',\n",
              " '223',\n",
              " '224',\n",
              " '225',\n",
              " '226',\n",
              " '227',\n",
              " '228',\n",
              " '229',\n",
              " '230',\n",
              " '231',\n",
              " '232',\n",
              " '233',\n",
              " '234',\n",
              " '235',\n",
              " '236',\n",
              " '237',\n",
              " '238',\n",
              " '239',\n",
              " '240',\n",
              " '241',\n",
              " '242',\n",
              " '243',\n",
              " '244',\n",
              " '245',\n",
              " '246',\n",
              " '247',\n",
              " '248',\n",
              " '249',\n",
              " '250',\n",
              " '251',\n",
              " '252',\n",
              " '253',\n",
              " '254',\n",
              " '255',\n",
              " '256',\n",
              " '257',\n",
              " '258',\n",
              " '259',\n",
              " '260',\n",
              " '261',\n",
              " '262',\n",
              " '263',\n",
              " '264',\n",
              " '265',\n",
              " '266',\n",
              " '267',\n",
              " '268',\n",
              " '269',\n",
              " '270',\n",
              " '271',\n",
              " '272',\n",
              " '273',\n",
              " '274',\n",
              " '275',\n",
              " '276',\n",
              " '277',\n",
              " '278',\n",
              " '279',\n",
              " '280',\n",
              " '281',\n",
              " '282',\n",
              " '283',\n",
              " '284',\n",
              " '285',\n",
              " '286',\n",
              " '287',\n",
              " '288',\n",
              " '289',\n",
              " '290',\n",
              " '291',\n",
              " '292',\n",
              " '293',\n",
              " '294',\n",
              " '295',\n",
              " '296',\n",
              " '297',\n",
              " '298',\n",
              " '299',\n",
              " '300',\n",
              " '301',\n",
              " '302',\n",
              " '303',\n",
              " '304',\n",
              " '305',\n",
              " '306',\n",
              " '307',\n",
              " '308',\n",
              " '309',\n",
              " '310',\n",
              " '311',\n",
              " '312',\n",
              " '313',\n",
              " '314',\n",
              " '315',\n",
              " '316',\n",
              " '317',\n",
              " '318',\n",
              " '319',\n",
              " '320',\n",
              " '321',\n",
              " '322',\n",
              " '323',\n",
              " '324',\n",
              " '325',\n",
              " '326',\n",
              " '327',\n",
              " '328',\n",
              " '329',\n",
              " '330',\n",
              " '331',\n",
              " '332',\n",
              " '333',\n",
              " '334',\n",
              " '335',\n",
              " '336',\n",
              " '337',\n",
              " '338',\n",
              " '339',\n",
              " '340',\n",
              " '341',\n",
              " '342',\n",
              " '343',\n",
              " '344',\n",
              " '345',\n",
              " '346',\n",
              " '347',\n",
              " '348',\n",
              " '349',\n",
              " '350',\n",
              " '351',\n",
              " '352',\n",
              " '353',\n",
              " '354',\n",
              " '355',\n",
              " '356',\n",
              " '357',\n",
              " '358',\n",
              " '359',\n",
              " '360',\n",
              " '361',\n",
              " '362',\n",
              " '363',\n",
              " '364',\n",
              " '365',\n",
              " '366',\n",
              " '367',\n",
              " '368',\n",
              " '369',\n",
              " '370',\n",
              " '371',\n",
              " '372',\n",
              " '373',\n",
              " '374',\n",
              " '375',\n",
              " '376',\n",
              " '377',\n",
              " '378',\n",
              " '379',\n",
              " '380',\n",
              " '381',\n",
              " '382',\n",
              " '383',\n",
              " '384',\n",
              " '385',\n",
              " '386',\n",
              " '387',\n",
              " '388',\n",
              " '389',\n",
              " '390',\n",
              " '391',\n",
              " '392',\n",
              " '393',\n",
              " '394',\n",
              " '395',\n",
              " '396',\n",
              " '397',\n",
              " '398',\n",
              " '399',\n",
              " '400',\n",
              " '401',\n",
              " '402',\n",
              " '403',\n",
              " '404',\n",
              " '405',\n",
              " '406',\n",
              " '407',\n",
              " '408',\n",
              " '409',\n",
              " '410',\n",
              " '411',\n",
              " '412',\n",
              " '413',\n",
              " '414',\n",
              " '415',\n",
              " '416',\n",
              " '417',\n",
              " '418',\n",
              " '419',\n",
              " '420',\n",
              " '421',\n",
              " '422',\n",
              " '423',\n",
              " '424',\n",
              " '425',\n",
              " '426',\n",
              " '427',\n",
              " '428',\n",
              " '429',\n",
              " '430',\n",
              " '431',\n",
              " '432',\n",
              " '433',\n",
              " '434',\n",
              " '435',\n",
              " '436',\n",
              " '437',\n",
              " '438',\n",
              " '439',\n",
              " '440',\n",
              " '441',\n",
              " '442',\n",
              " '443',\n",
              " '444',\n",
              " '445',\n",
              " '446',\n",
              " '447',\n",
              " '448',\n",
              " '449',\n",
              " '450',\n",
              " '451',\n",
              " '452',\n",
              " '453',\n",
              " '454',\n",
              " '455',\n",
              " '456',\n",
              " '457',\n",
              " '458',\n",
              " '459',\n",
              " '460',\n",
              " '461',\n",
              " '462',\n",
              " '463',\n",
              " '464',\n",
              " '465',\n",
              " '466',\n",
              " '467',\n",
              " '468',\n",
              " '469',\n",
              " '470',\n",
              " '471',\n",
              " '472',\n",
              " '473',\n",
              " '474',\n",
              " '475',\n",
              " '476',\n",
              " '477',\n",
              " '478',\n",
              " '479',\n",
              " '480',\n",
              " '481',\n",
              " '482',\n",
              " '483',\n",
              " '484',\n",
              " '485',\n",
              " '486',\n",
              " '487',\n",
              " '488',\n",
              " '489',\n",
              " '490',\n",
              " '491',\n",
              " '492',\n",
              " '493',\n",
              " '494',\n",
              " '495',\n",
              " '496',\n",
              " '497',\n",
              " '498',\n",
              " '499',\n",
              " '500',\n",
              " '501',\n",
              " '502',\n",
              " '503',\n",
              " '504',\n",
              " '505',\n",
              " '506',\n",
              " '507',\n",
              " '508',\n",
              " '509',\n",
              " '510',\n",
              " '511',\n",
              " 'label']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocK87Gcrqrnv",
        "colab_type": "text"
      },
      "source": [
        "Initalization of sets according to LightGB . it is optional"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDxEIbSxN8VV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import lightgbm as lgb\n",
        "import gc\n",
        "gc.collect()\n",
        "\n",
        "dtrain = lgb.Dataset(dftrain[featureCol[:512]].values, label=dftrain['label'].values,\n",
        "                      feature_name=featureCol[:512]\n",
        "                      )\n",
        "dvalid = lgb.Dataset(dfvalid[featureCol[:512]].values, label=dftest['label'].values,\n",
        "                      feature_name=featureCol[:512],\n",
        "                      )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vo5dTDysqzqp",
        "colab_type": "text"
      },
      "source": [
        "Initial Paramets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xa4pXDWnrgba",
        "colab_type": "text"
      },
      "source": [
        "#Random Search for Hyperparamters Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmkfCsnIq3KS",
        "colab_type": "text"
      },
      "source": [
        "Some Parameters are initalization as a population. On which we performs Random Search / Grid Search to Choose Optimal Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5v6HRU64Hqg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# gridParams = {\n",
        "#     'learning_rate': [0.13,0.4,0.3,0.35,0.1,0.23,0.2,0.15],\n",
        "#     'n_estimators': [40,100,120,12,20,50,90,140,105],\n",
        "#     'num_leaves': [100,200,300,40,60,50,350,400],\n",
        "#     'boosting_type' : ['gbdt'],\n",
        "#     'objective' : ['binary'],\n",
        "#     'random_state' : [501], # Updated from 'seed'\n",
        "#     'colsample_bytree' : [0.65,0.9,0.7,0.85, 0.66,0.7,0.9],\n",
        "    \n",
        "    \n",
        "#     }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETdvDE1mOvVk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# mdl = lgb.LGBMClassifier(\n",
        "                        \n",
        "#                         )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Xr7L8ek5K8I",
        "colab_type": "code",
        "outputId": "442ef95c-d336-4dd7-c506-7318bf9da2b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# mdl.get_params().keys()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['boosting_type', 'class_weight', 'colsample_bytree', 'importance_type', 'learning_rate', 'max_depth', 'min_child_samples', 'min_child_weight', 'min_split_gain', 'n_estimators', 'n_jobs', 'num_leaves', 'objective', 'random_state', 'reg_alpha', 'reg_lambda', 'silent', 'subsample', 'subsample_for_bin', 'subsample_freq'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZ5delpcrHuG",
        "colab_type": "text"
      },
      "source": [
        "Random Search with 100 Iteration , it takes very large time so I am commiting the code beacause we get optimal values which are below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1G1gE4ArgBy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "def evaluate_macroF1_lgb(truth, predictions): \n",
        "    for i in range(len(predictions)):\n",
        "        if predictions[i]>=.6:       # setting threshold to .5\n",
        "            predictions[i]=1\n",
        "        else:  \n",
        "            predictions[i]=0\n",
        "    f1 = f1_score(truth, np.round(predictions), average='binary')\n",
        "    f1 = f1_score(truth, predictions, average='binary')\n",
        "    return ('macroF1', f1, True) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNPd1lKt5LAY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import (roc_curve, auc, accuracy_score)\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "\n",
        "gridParams = {\n",
        "    'learning_rate': [0.13,0.4,0.3,0.35,0.1,0.23,0.2,0.15],\n",
        "    'n_estimators': [40,100,120,12,20,50,90,140,105],\n",
        "    'num_leaves': [100,200,300,40,60,50,350,400],\n",
        "    'boosting_type' : ['gbdt'],\n",
        "    'objective' : ['binary'],\n",
        "    'random_state' : [501], # Updated from 'seed'\n",
        "    'colsample_bytree' : [0.65,0.9,0.7,0.85, 0.66,0.7,0.9],\n",
        "    'max_depth' :[15,20,30,35,42,40,60,100,90,80],\n",
        "    'min_child_samples': [100,200,30,40,20,60,80,90]  \n",
        "    \n",
        "    }\n",
        "gs = RandomizedSearchCV(\n",
        "    estimator=mdl, param_distributions=gridParams, \n",
        "    n_iter=500,\n",
        "    scoring='f1_macro',\n",
        "    cv=2,\n",
        "    n_jobs=1,\n",
        "    refit=True,\n",
        "    random_state=314,\n",
        "    verbose=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwVhWf9UvwKS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fit_params={\"early_stopping_rounds\":50, \n",
        "            \"eval_metric\" : 'binary_logloss', \n",
        "            \"eval_set\" : [dfvalid],\n",
        "            'eval_names': ['valid'],\n",
        "            #'callbacks': [lgb.reset_parameter(learning_rate=learning_rate_010_decay_power_099)],\n",
        "            'verbose': 1,\n",
        "            'categorical_feature': 'auto'}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k57hQoPb5-FP",
        "colab_type": "code",
        "outputId": "016b3108-0e3c-4219-e984-6023263025d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "gs.fit(dftrain[testCol], dftrain['label'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 500 candidates, totalling 1000 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed: 29.2min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=2, error_score='raise-deprecating',\n",
              "                   estimator=LGBMClassifier(boosting_type='gbdt',\n",
              "                                            class_weight=None,\n",
              "                                            colsample_bytree=0.6,\n",
              "                                            eval_metric=('binary_logloss',),\n",
              "                                            importance_type='split',\n",
              "                                            learning_rate=0.01, max_bin=(90,),\n",
              "                                            max_depth=15,\n",
              "                                            min_child_samples=(100,),\n",
              "                                            min_child_weight=0.2, min_data=30,\n",
              "                                            min_split_gain=0.0,\n",
              "                                            n_estimators=100, n_jobs=-1,\n",
              "                                            num...\n",
              "                                                          0.1, 0.23, 0.2,\n",
              "                                                          0.15],\n",
              "                                        'max_depth': [15, 20, 30, 35, 42, 40,\n",
              "                                                      60, 100, 90, 80],\n",
              "                                        'min_child_samples': [100, 200, 30, 40,\n",
              "                                                              20, 60, 80, 90],\n",
              "                                        'n_estimators': [40, 100, 120, 12, 20,\n",
              "                                                         50, 90, 140, 105],\n",
              "                                        'num_leaves': [100, 200, 300, 40, 60,\n",
              "                                                       50, 350, 400],\n",
              "                                        'objective': ['binary'],\n",
              "                                        'random_state': [501]},\n",
              "                   pre_dispatch='2*n_jobs', random_state=314, refit=True,\n",
              "                   return_train_score=False, scoring='f1_macro', verbose=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8TnYW5nrsNz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUFKZ2Hkrt33",
        "colab_type": "text"
      },
      "source": [
        "#Train Model WIth Best Parameters Optimized by Random Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrsahrKv3O1i",
        "colab_type": "code",
        "outputId": "14d35716-0623-4423-c283-18e4cfce376e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print('Best score reached: {} with params: {} '.format(gs.best_score_, gs.best_params_))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best score reached: 0.9554476039754403 with params: {'random_state': 501, 'objective': 'binary', 'num_leaves': 350, 'n_estimators': 40, 'min_child_samples': 30, 'max_depth': 15, 'learning_rate': 0.2, 'colsample_bytree': 0.9, 'boosting_type': 'gbdt'} \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kI_7vxAhzI97",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bestParams=gs.best_params_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lViGr7KC3DbF",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxH-AYlUJ9cz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bestParams={'random_state': 501, 'objective': 'binary', 'num_leaves': 20, 'n_estimators': 50, 'learning_rate': 0.1, 'colsample_bytree': 0.6, 'boosting_type': 'gbdt'}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvIcGXRU4ETj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params={'random_state': 501, 'objective': 'binary', 'num_leaves': 20, 'n_estimators': 100, 'learning_rate': 0.01, 'colsample_bytree': 0.6, 'boosting_type': 'gbdt'}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHqXFS2f3amU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bestParams['min_data'] = 30\n",
        "bestParams[\"num_iterations\"]=1000\n",
        "bestParams['max_depth'] = 300\n",
        "bestParams['min_child_samples']= 100,  \n",
        "bestParams['max_bin']=100,  \n",
        "bestParams['min_child_weight']=0.3\n",
        "bestParams[\"eval_metric\" ]= 'binary_logloss', "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrZXs6Bt6THG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fit_params={\"early_stopping_rounds\":100, \n",
        "            \"eval_metric\" : 'binary_logloss', \n",
        "            \"eval_set\" : [(dfvalid[testCol],dfvalid['label'])],\n",
        "            'eval_names': ['valid'],\n",
        "           \n",
        "            #'callbacks': [lgb.reset_parameter(learning_rate=learning_rate_010_decay_power_099)],\n",
        "            'verbose': 1,\n",
        "            'categorical_feature': 'auto'}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUilNloz5LGw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "mdl = lgb.LGBMClassifier(\n",
        "                        \n",
        "                         **bestParams,\n",
        "    \n",
        "                        )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1joxRIS5LJ7",
        "colab_type": "code",
        "outputId": "5d5cbe09-cf74-45c1-d6be-e0065ca7005c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "\n",
        "mdl.fit(dftrain[testCol],dftrain['label'],**fit_params)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1]\tvalid's binary_logloss: 0.600283\tvalid's binary_logloss: 0.600283\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[2]\tvalid's binary_logloss: 0.534699\tvalid's binary_logloss: 0.534699\n",
            "[3]\tvalid's binary_logloss: 0.480882\tvalid's binary_logloss: 0.480882\n",
            "[4]\tvalid's binary_logloss: 0.435181\tvalid's binary_logloss: 0.435181\n",
            "[5]\tvalid's binary_logloss: 0.396356\tvalid's binary_logloss: 0.396356\n",
            "[6]\tvalid's binary_logloss: 0.362948\tvalid's binary_logloss: 0.362948\n",
            "[7]\tvalid's binary_logloss: 0.334793\tvalid's binary_logloss: 0.334793\n",
            "[8]\tvalid's binary_logloss: 0.310614\tvalid's binary_logloss: 0.310614\n",
            "[9]\tvalid's binary_logloss: 0.289243\tvalid's binary_logloss: 0.289243\n",
            "[10]\tvalid's binary_logloss: 0.270996\tvalid's binary_logloss: 0.270996\n",
            "[11]\tvalid's binary_logloss: 0.254898\tvalid's binary_logloss: 0.254898\n",
            "[12]\tvalid's binary_logloss: 0.240602\tvalid's binary_logloss: 0.240602\n",
            "[13]\tvalid's binary_logloss: 0.228036\tvalid's binary_logloss: 0.228036\n",
            "[14]\tvalid's binary_logloss: 0.216707\tvalid's binary_logloss: 0.216707\n",
            "[15]\tvalid's binary_logloss: 0.206329\tvalid's binary_logloss: 0.206329\n",
            "[16]\tvalid's binary_logloss: 0.197893\tvalid's binary_logloss: 0.197893\n",
            "[17]\tvalid's binary_logloss: 0.190691\tvalid's binary_logloss: 0.190691\n",
            "[18]\tvalid's binary_logloss: 0.184309\tvalid's binary_logloss: 0.184309\n",
            "[19]\tvalid's binary_logloss: 0.178957\tvalid's binary_logloss: 0.178957\n",
            "[20]\tvalid's binary_logloss: 0.173564\tvalid's binary_logloss: 0.173564\n",
            "[21]\tvalid's binary_logloss: 0.168412\tvalid's binary_logloss: 0.168412\n",
            "[22]\tvalid's binary_logloss: 0.164264\tvalid's binary_logloss: 0.164264\n",
            "[23]\tvalid's binary_logloss: 0.159841\tvalid's binary_logloss: 0.159841\n",
            "[24]\tvalid's binary_logloss: 0.157687\tvalid's binary_logloss: 0.157687\n",
            "[25]\tvalid's binary_logloss: 0.154171\tvalid's binary_logloss: 0.154171\n",
            "[26]\tvalid's binary_logloss: 0.151251\tvalid's binary_logloss: 0.151251\n",
            "[27]\tvalid's binary_logloss: 0.149312\tvalid's binary_logloss: 0.149312\n",
            "[28]\tvalid's binary_logloss: 0.147278\tvalid's binary_logloss: 0.147278\n",
            "[29]\tvalid's binary_logloss: 0.145706\tvalid's binary_logloss: 0.145706\n",
            "[30]\tvalid's binary_logloss: 0.145646\tvalid's binary_logloss: 0.145646\n",
            "[31]\tvalid's binary_logloss: 0.14481\tvalid's binary_logloss: 0.14481\n",
            "[32]\tvalid's binary_logloss: 0.145382\tvalid's binary_logloss: 0.145382\n",
            "[33]\tvalid's binary_logloss: 0.14466\tvalid's binary_logloss: 0.14466\n",
            "[34]\tvalid's binary_logloss: 0.143948\tvalid's binary_logloss: 0.143948\n",
            "[35]\tvalid's binary_logloss: 0.143759\tvalid's binary_logloss: 0.143759\n",
            "[36]\tvalid's binary_logloss: 0.143972\tvalid's binary_logloss: 0.143972\n",
            "[37]\tvalid's binary_logloss: 0.144434\tvalid's binary_logloss: 0.144434\n",
            "[38]\tvalid's binary_logloss: 0.144419\tvalid's binary_logloss: 0.144419\n",
            "[39]\tvalid's binary_logloss: 0.14388\tvalid's binary_logloss: 0.14388\n",
            "[40]\tvalid's binary_logloss: 0.144247\tvalid's binary_logloss: 0.144247\n",
            "[41]\tvalid's binary_logloss: 0.144209\tvalid's binary_logloss: 0.144209\n",
            "[42]\tvalid's binary_logloss: 0.144635\tvalid's binary_logloss: 0.144635\n",
            "[43]\tvalid's binary_logloss: 0.145232\tvalid's binary_logloss: 0.145232\n",
            "[44]\tvalid's binary_logloss: 0.14453\tvalid's binary_logloss: 0.14453\n",
            "[45]\tvalid's binary_logloss: 0.144765\tvalid's binary_logloss: 0.144765\n",
            "[46]\tvalid's binary_logloss: 0.144967\tvalid's binary_logloss: 0.144967\n",
            "[47]\tvalid's binary_logloss: 0.144684\tvalid's binary_logloss: 0.144684\n",
            "[48]\tvalid's binary_logloss: 0.144689\tvalid's binary_logloss: 0.144689\n",
            "[49]\tvalid's binary_logloss: 0.144311\tvalid's binary_logloss: 0.144311\n",
            "[50]\tvalid's binary_logloss: 0.14427\tvalid's binary_logloss: 0.14427\n",
            "[51]\tvalid's binary_logloss: 0.144654\tvalid's binary_logloss: 0.144654\n",
            "[52]\tvalid's binary_logloss: 0.145511\tvalid's binary_logloss: 0.145511\n",
            "[53]\tvalid's binary_logloss: 0.146306\tvalid's binary_logloss: 0.146306\n",
            "[54]\tvalid's binary_logloss: 0.147265\tvalid's binary_logloss: 0.147265\n",
            "[55]\tvalid's binary_logloss: 0.148928\tvalid's binary_logloss: 0.148928\n",
            "[56]\tvalid's binary_logloss: 0.14976\tvalid's binary_logloss: 0.14976\n",
            "[57]\tvalid's binary_logloss: 0.149939\tvalid's binary_logloss: 0.149939\n",
            "[58]\tvalid's binary_logloss: 0.149613\tvalid's binary_logloss: 0.149613\n",
            "[59]\tvalid's binary_logloss: 0.15112\tvalid's binary_logloss: 0.15112\n",
            "[60]\tvalid's binary_logloss: 0.151248\tvalid's binary_logloss: 0.151248\n",
            "[61]\tvalid's binary_logloss: 0.153005\tvalid's binary_logloss: 0.153005\n",
            "[62]\tvalid's binary_logloss: 0.153603\tvalid's binary_logloss: 0.153603\n",
            "[63]\tvalid's binary_logloss: 0.154825\tvalid's binary_logloss: 0.154825\n",
            "[64]\tvalid's binary_logloss: 0.155494\tvalid's binary_logloss: 0.155494\n",
            "[65]\tvalid's binary_logloss: 0.15653\tvalid's binary_logloss: 0.15653\n",
            "[66]\tvalid's binary_logloss: 0.158519\tvalid's binary_logloss: 0.158519\n",
            "[67]\tvalid's binary_logloss: 0.159089\tvalid's binary_logloss: 0.159089\n",
            "[68]\tvalid's binary_logloss: 0.160085\tvalid's binary_logloss: 0.160085\n",
            "[69]\tvalid's binary_logloss: 0.16162\tvalid's binary_logloss: 0.16162\n",
            "[70]\tvalid's binary_logloss: 0.161506\tvalid's binary_logloss: 0.161506\n",
            "[71]\tvalid's binary_logloss: 0.162006\tvalid's binary_logloss: 0.162006\n",
            "[72]\tvalid's binary_logloss: 0.16262\tvalid's binary_logloss: 0.16262\n",
            "[73]\tvalid's binary_logloss: 0.163226\tvalid's binary_logloss: 0.163226\n",
            "[74]\tvalid's binary_logloss: 0.163076\tvalid's binary_logloss: 0.163076\n",
            "[75]\tvalid's binary_logloss: 0.163497\tvalid's binary_logloss: 0.163497\n",
            "[76]\tvalid's binary_logloss: 0.164532\tvalid's binary_logloss: 0.164532\n",
            "[77]\tvalid's binary_logloss: 0.164705\tvalid's binary_logloss: 0.164705\n",
            "[78]\tvalid's binary_logloss: 0.165322\tvalid's binary_logloss: 0.165322\n",
            "[79]\tvalid's binary_logloss: 0.166132\tvalid's binary_logloss: 0.166132\n",
            "[80]\tvalid's binary_logloss: 0.167308\tvalid's binary_logloss: 0.167308\n",
            "[81]\tvalid's binary_logloss: 0.168079\tvalid's binary_logloss: 0.168079\n",
            "[82]\tvalid's binary_logloss: 0.168686\tvalid's binary_logloss: 0.168686\n",
            "[83]\tvalid's binary_logloss: 0.170298\tvalid's binary_logloss: 0.170298\n",
            "[84]\tvalid's binary_logloss: 0.171321\tvalid's binary_logloss: 0.171321\n",
            "[85]\tvalid's binary_logloss: 0.171638\tvalid's binary_logloss: 0.171638\n",
            "[86]\tvalid's binary_logloss: 0.173172\tvalid's binary_logloss: 0.173172\n",
            "[87]\tvalid's binary_logloss: 0.174723\tvalid's binary_logloss: 0.174723\n",
            "[88]\tvalid's binary_logloss: 0.175496\tvalid's binary_logloss: 0.175496\n",
            "[89]\tvalid's binary_logloss: 0.175317\tvalid's binary_logloss: 0.175317\n",
            "[90]\tvalid's binary_logloss: 0.17664\tvalid's binary_logloss: 0.17664\n",
            "[91]\tvalid's binary_logloss: 0.17777\tvalid's binary_logloss: 0.17777\n",
            "[92]\tvalid's binary_logloss: 0.179289\tvalid's binary_logloss: 0.179289\n",
            "[93]\tvalid's binary_logloss: 0.179695\tvalid's binary_logloss: 0.179695\n",
            "[94]\tvalid's binary_logloss: 0.179839\tvalid's binary_logloss: 0.179839\n",
            "[95]\tvalid's binary_logloss: 0.180833\tvalid's binary_logloss: 0.180833\n",
            "[96]\tvalid's binary_logloss: 0.181335\tvalid's binary_logloss: 0.181335\n",
            "[97]\tvalid's binary_logloss: 0.181994\tvalid's binary_logloss: 0.181994\n",
            "[98]\tvalid's binary_logloss: 0.183078\tvalid's binary_logloss: 0.183078\n",
            "[99]\tvalid's binary_logloss: 0.183818\tvalid's binary_logloss: 0.183818\n",
            "[100]\tvalid's binary_logloss: 0.184575\tvalid's binary_logloss: 0.184575\n",
            "[101]\tvalid's binary_logloss: 0.18575\tvalid's binary_logloss: 0.18575\n",
            "[102]\tvalid's binary_logloss: 0.186533\tvalid's binary_logloss: 0.186533\n",
            "[103]\tvalid's binary_logloss: 0.187456\tvalid's binary_logloss: 0.187456\n",
            "[104]\tvalid's binary_logloss: 0.189494\tvalid's binary_logloss: 0.189494\n",
            "[105]\tvalid's binary_logloss: 0.189927\tvalid's binary_logloss: 0.189927\n",
            "[106]\tvalid's binary_logloss: 0.190697\tvalid's binary_logloss: 0.190697\n",
            "[107]\tvalid's binary_logloss: 0.191896\tvalid's binary_logloss: 0.191896\n",
            "[108]\tvalid's binary_logloss: 0.193298\tvalid's binary_logloss: 0.193298\n",
            "[109]\tvalid's binary_logloss: 0.194152\tvalid's binary_logloss: 0.194152\n",
            "[110]\tvalid's binary_logloss: 0.194783\tvalid's binary_logloss: 0.194783\n",
            "[111]\tvalid's binary_logloss: 0.196591\tvalid's binary_logloss: 0.196591\n",
            "[112]\tvalid's binary_logloss: 0.197378\tvalid's binary_logloss: 0.197378\n",
            "[113]\tvalid's binary_logloss: 0.197975\tvalid's binary_logloss: 0.197975\n",
            "[114]\tvalid's binary_logloss: 0.198504\tvalid's binary_logloss: 0.198504\n",
            "[115]\tvalid's binary_logloss: 0.199711\tvalid's binary_logloss: 0.199711\n",
            "[116]\tvalid's binary_logloss: 0.2008\tvalid's binary_logloss: 0.2008\n",
            "[117]\tvalid's binary_logloss: 0.20133\tvalid's binary_logloss: 0.20133\n",
            "[118]\tvalid's binary_logloss: 0.201716\tvalid's binary_logloss: 0.201716\n",
            "[119]\tvalid's binary_logloss: 0.20328\tvalid's binary_logloss: 0.20328\n",
            "[120]\tvalid's binary_logloss: 0.203287\tvalid's binary_logloss: 0.203287\n",
            "[121]\tvalid's binary_logloss: 0.204097\tvalid's binary_logloss: 0.204097\n",
            "[122]\tvalid's binary_logloss: 0.204905\tvalid's binary_logloss: 0.204905\n",
            "[123]\tvalid's binary_logloss: 0.205637\tvalid's binary_logloss: 0.205637\n",
            "[124]\tvalid's binary_logloss: 0.206131\tvalid's binary_logloss: 0.206131\n",
            "[125]\tvalid's binary_logloss: 0.206878\tvalid's binary_logloss: 0.206878\n",
            "[126]\tvalid's binary_logloss: 0.207768\tvalid's binary_logloss: 0.207768\n",
            "[127]\tvalid's binary_logloss: 0.208372\tvalid's binary_logloss: 0.208372\n",
            "[128]\tvalid's binary_logloss: 0.209637\tvalid's binary_logloss: 0.209637\n",
            "[129]\tvalid's binary_logloss: 0.21045\tvalid's binary_logloss: 0.21045\n",
            "[130]\tvalid's binary_logloss: 0.210854\tvalid's binary_logloss: 0.210854\n",
            "[131]\tvalid's binary_logloss: 0.211524\tvalid's binary_logloss: 0.211524\n",
            "[132]\tvalid's binary_logloss: 0.211183\tvalid's binary_logloss: 0.211183\n",
            "[133]\tvalid's binary_logloss: 0.212212\tvalid's binary_logloss: 0.212212\n",
            "[134]\tvalid's binary_logloss: 0.213171\tvalid's binary_logloss: 0.213171\n",
            "[135]\tvalid's binary_logloss: 0.213657\tvalid's binary_logloss: 0.213657\n",
            "Early stopping, best iteration is:\n",
            "[35]\tvalid's binary_logloss: 0.143759\tvalid's binary_logloss: 0.143759\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,\n",
              "               eval_metric=('binary_logloss',), importance_type='split',\n",
              "               learning_rate=0.1, max_bin=(100,), max_depth=300,\n",
              "               min_child_samples=(100,), min_child_weight=0.3, min_data=30,\n",
              "               min_split_gain=0.0, n_estimators=50, n_jobs=-1,\n",
              "               num_iterations=1000, num_leaves=20, objective='binary',\n",
              "               random_state=501, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
              "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 227
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sBFbnQPXWlj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lab=dftest['label']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_r7Lmz_OXy2d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dftest1=dftest.drop('label',axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnGW1lyUwJ7u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7_DzRm2Tb8B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "y_pred=mdl.predict(dftest1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEkyAHZmYUyd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(y_pred)):\n",
        "    if y_pred[i]>=.4:       # setting threshold to .5\n",
        "       y_pred[i]=1\n",
        "    else:  \n",
        "       y_pred[i]=0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhpW9YqVQtr3",
        "colab_type": "code",
        "outputId": "bff83bfe-cc9a-4bac-bd0c-ee3de434bb9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(lab, y_pred)\n",
        "#Accuracy\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy=accuracy_score(y_pred,lab)\n",
        "print(accuracy)\n",
        "print(cm)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.970108695652174\n",
            "[[142   4]\n",
            " [  7 215]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i84zIAKpkZaY",
        "colab_type": "text"
      },
      "source": [
        "Calculating Values according to\n",
        "$$ Recall = \\frac{TruePositive}{TruePositive+False Nagitive}=0.9705215419501134\n",
        "$$ Precision = \\frac{TruePositive}{TruePositive+FalsePositive}$$\n",
        "$$F1 = \\frac{2 \\cdot precision\\cdot recall}{precision+ recall}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJmuzKEJSO-A",
        "colab_type": "code",
        "outputId": "d1ead9ec-eb59-403f-9554-de962a0f2063",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "conf=cm\n",
        "TrueNagitive=conf[0][0]\n",
        "FalseNegative=conf[0][1]\n",
        "TruePositive=conf[1][1]\n",
        "FalsePositive=conf[1][0]\n",
        "recal=TruePositive/(TruePositive+FalseNegative)\n",
        "precision=TruePositive/(TruePositive+FalsePositive)\n",
        "print(\"Precision of Model =\",precision,\"Recall of Model \", recal)\n",
        "f1=2*((precision*recal)/(precision+recal))\n",
        "print('F1 Score of Model =',f1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision of Model = 0.9684684684684685 Recall of Model  0.9817351598173516\n",
            "F1 Score of Model = 0.9750566893424036\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RoQEdC6r-gp",
        "colab_type": "text"
      },
      "source": [
        "Learning Curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i59-4YRXA2o7",
        "colab_type": "code",
        "outputId": "161e93e5-3c8e-405e-c210-dfab0b9a980b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        }
      },
      "source": [
        "print(__doc__)\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import learning_curve\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "\n",
        "\n",
        "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
        "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
        "    \"\"\"\n",
        "    Generate a simple plot of the test and training learning curve.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
        "        An object of that type which is cloned for each validation.\n",
        "\n",
        "    title : string\n",
        "        Title for the chart.\n",
        "\n",
        "    X : array-like, shape (n_samples, n_features)\n",
        "        Training vector, where n_samples is the number of samples and\n",
        "        n_features is the number of features.\n",
        "\n",
        "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
        "        Target relative to X for classification or regression;\n",
        "        None for unsupervised learning.\n",
        "\n",
        "    ylim : tuple, shape (ymin, ymax), optional\n",
        "        Defines minimum and maximum yvalues plotted.\n",
        "\n",
        "    cv : int, cross-validation generator or an iterable, optional\n",
        "        Determines the cross-validation splitting strategy.\n",
        "        Possible inputs for cv are:\n",
        "          - None, to use the default 3-fold cross-validation,\n",
        "          - integer, to specify the number of folds.\n",
        "          - :term:`CV splitter`,\n",
        "          - An iterable yielding (train, test) splits as arrays of indices.\n",
        "\n",
        "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
        "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
        "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
        "\n",
        "        Refer :ref:`User Guide <cross_validation>` for the various\n",
        "        cross-validators that can be used here.\n",
        "\n",
        "    n_jobs : int or None, optional (default=None)\n",
        "        Number of jobs to run in parallel.\n",
        "        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
        "        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
        "        for more details.\n",
        "\n",
        "    train_sizes : array-like, shape (n_ticks,), dtype float or int\n",
        "        Relative or absolute numbers of training examples that will be used to\n",
        "        generate the learning curve. If the dtype is float, it is regarded as a\n",
        "        fraction of the maximum size of the training set (that is determined\n",
        "        by the selected validation method), i.e. it has to be within (0, 1].\n",
        "        Otherwise it is interpreted as absolute sizes of the training sets.\n",
        "        Note that for classification the number of samples usually have to\n",
        "        be big enough to contain at least one sample from each class.\n",
        "        (default: np.linspace(0.1, 1.0, 5))\n",
        "    \"\"\"\n",
        "    plt.figure()\n",
        "    plt.title(title)\n",
        "    if ylim is not None:\n",
        "        plt.ylim(*ylim)\n",
        "    plt.xlabel(\"Training examples\")\n",
        "    plt.ylabel(\"Score\")\n",
        "    train_sizes, train_scores, test_scores = learning_curve(\n",
        "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "    plt.grid()\n",
        "\n",
        "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
        "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
        "                     color=\"r\")\n",
        "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
        "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
        "    plt.plot(train_sizes, train_scores_mean,\n",
        "             label=\"Training score\")\n",
        "    plt.plot(train_sizes, test_scores_mean,\n",
        "             label=\"Validation\")\n",
        "\n",
        "    plt.legend(loc=\"best\")\n",
        "    return plt\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "title = \"Light GBM Learning Curve Resnet34 Features\"\n",
        "# Cross validation with 100 iterations to get smoother mean test and train\n",
        "# score curves, each time with 20% data randomly selected as a validation set.\n",
        "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=42)\n",
        "\n",
        "estimator=lgb.LGBMClassifier(\n",
        "                        boosting_type='gbdt',\n",
        "          objective = 'binary',\n",
        "          n_jobs = 2, # Updated from 'nthread'\n",
        "          silent = True,\n",
        "                     random_state=501,\n",
        "                         num_leaves=300,\n",
        "                         n_estimators=80,\n",
        "                         learning_rate=0.1,\n",
        "                         colsample_bytree=0.85,\n",
        "                         \n",
        "                        )\n",
        "plot_learning_curve(mdl, title, dataset[testCol],dataset['label'], ylim=(0.7, 1.01), cv=cv, n_jobs=4)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Automatically created module for IPython interactive environment\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nB7X7bLFBHAqOAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEHhPk8WAk6G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}